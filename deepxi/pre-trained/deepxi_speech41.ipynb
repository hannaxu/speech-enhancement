{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepxi_speech41_medium.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqC7TkwKXXRb"
      },
      "source": [
        "!pip3 install deepspeech-gpu==0.4.1\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.4.1/deepspeech-0.4.1-models.tar.gz\n",
        "!tar xvfz deepspeech-0.4.1-models.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r30dwdKjXj2d"
      },
      "source": [
        "# change cuda version\n",
        "%tensorflow_version 1.x\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf adversarial_examples_A.tar.gz\n",
        "!tar -xf enhanced_A.tar.gz"
      ],
      "metadata": {
        "id": "5aGfQkhW0KJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "# from jiwer import compute_measures\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "PFLV0ajQWBoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrObS5PbX2cY"
      },
      "source": [
        "def convert(audio):\n",
        "  stream = os.popen(f'deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio {audio}')\n",
        "  output = stream.read()\n",
        "  return output.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBcUiV6zvqhQ"
      },
      "source": [
        "enh_path = './DeepXi/out/mhanet-1.1c/mmse-lsa'\n",
        "adv_path = './DeepXi/Adversarial_Examples'\n",
        "grounds = ['/long-ground.txt', '/medium-ground.txt', '/short-ground.txt']\n",
        "files = ['/long-signals.txt', '/medium-signals.txt', '/short-signals.txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert(adv_path+'/sample-000003.wav')"
      ],
      "metadata": {
        "id": "izL8Zhs51nGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSFPOYVPz-zp"
      },
      "source": [
        "trans_dict = {}\n",
        "translations = []\n",
        "for f, g in zip(files, grounds):\n",
        "  t = open(adv_path+f, 'r')\n",
        "  text = t.read().strip().split('\\n')\n",
        "  gr = open(adv_path+g, 'r')\n",
        "  ground = gr.read().strip().split('\\n')\n",
        "  trans = {}\n",
        "  for i in range(2, 102):\n",
        "    temp = {}\n",
        "    temp['base'] = ground[i-2].split('\\t')[1]\n",
        "    ori_trans = convert(adv_path + '/' + text[i])\n",
        "    enh_ori_trans = convert(enh_path + '/' + text[i])\n",
        "    # long, medium, short adv\n",
        "    lms = (text[i+101], text[i+2*101], text[i+3*101])\n",
        "    adv_trans = [convert(adv_path+'/'+name) for name in lms]\n",
        "    enh_trans = [convert(enh_path+'/'+name) for name in lms]\n",
        "    temp['ori'] = ori_trans\n",
        "    temp['adv'] = adv_trans\n",
        "    temp['enh'] = enh_trans\n",
        "    temp['enh_ori'] = enh_ori_trans\n",
        "    trans[text[i]] = temp\n",
        "  with open(f'deepxi_trans1{len(translations)}.pickle', 'wb') as e:\n",
        "    pickle.dump(trans, e, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  translations.append(trans)\n",
        "  t.close()\n",
        "  gr.close()\n",
        "\n",
        "trans_dict['long'] = translations[0]\n",
        "trans_dict['medium'] = translations[1]\n",
        "trans_dict['short'] = translations[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_dict['long'] = translations[0]\n",
        "trans_dict['medium'] = translations[1]\n",
        "trans_dict['short'] = translations[2]"
      ],
      "metadata": {
        "id": "UeZilLUOcRRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_dict['short']['sample-006936.wav']"
      ],
      "metadata": {
        "id": "LuxL--RxwN66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('deepxi_trans1.pickle', 'wb') as e:\n",
        "  pickle.dump(trans_dict, e, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "PUCyjnwWwPfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer = {}\n",
        "with open('deepxi_trans1.pickle', 'rb') as e:\n",
        "  wer = pickle.load(e)"
      ],
      "metadata": {
        "id": "00DZnLAjwUGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer['short']['sample-006936.wav']"
      ],
      "metadata": {
        "id": "CZ8roJYDwWOs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}