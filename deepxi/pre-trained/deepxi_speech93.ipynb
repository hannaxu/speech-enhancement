{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepxi_speech93.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL9GFpNnvm1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd drive/MyDrive/IW06-07"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqC7TkwKXXRb"
      },
      "source": [
        "!pip3 install deepspeech-gpu\n",
        "!pip3 install jiwer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r30dwdKjXj2d"
      },
      "source": [
        "import deepspeech\n",
        "import wave\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from jiwer import compute_measures\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
      ],
      "metadata": {
        "id": "Rfi7AaBztJRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrObS5PbX2cY"
      },
      "source": [
        "model_file_path = 'deepspeech-0.9.3-models.pbmm'\n",
        "model = deepspeech.Model(model_file_path)\n",
        "scorer_file_path = 'deepspeech-0.9.3-models.scorer'\n",
        "model.enableExternalScorer(scorer_file_path)\n",
        "lm_alpha = 0.931289039105002\n",
        "lm_beta = 1.1834137581510284\n",
        "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "def convert(audio):\n",
        "  w = wave.open(audio, 'r')\n",
        "  assert int(w.getframerate()) == 16000\n",
        "  data = np.frombuffer(w.readframes(w.getnframes()), dtype=np.int16)\n",
        "  w.close()\n",
        "  return model.stt(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBcUiV6zvqhQ"
      },
      "source": [
        "enh_path = './deepxi/DeepXi/out/mhanet-1.1c/mmse-lsa/'\n",
        "adv_path = './deepxi/DeepXi/Adversarial_Examples'\n",
        "grounds = ['/long-ground.txt', '/medium-ground.txt', '/short-ground.txt']\n",
        "files = ['/long-signals.txt', '/medium-signals.txt', '/short-signals.txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSFPOYVPz-zp"
      },
      "source": [
        "trans_dict = {}\n",
        "translations = []\n",
        "for f, g in zip(files, grounds):\n",
        "  t = open(adv_path+f, 'r')\n",
        "  text = t.read().strip().split('\\n')\n",
        "  gr = open(adv_path+g, 'r')\n",
        "  ground = gr.read().strip().split('\\n')\n",
        "  trans = {}\n",
        "  for i in range(2, 102):\n",
        "    temp = {}\n",
        "    temp['base'] = ground[i-2].split('\\t')[1]\n",
        "    ori_trans = convert(adv_path + '/' + text[i])\n",
        "    enh_ori_trans = convert(enh_path + '/' + text[i])\n",
        "    # long, medium, short adv\n",
        "    lms = (text[i+101], text[i+2*101], text[i+3*101])\n",
        "    adv_trans = [convert(adv_path+'/'+name) for name in lms]\n",
        "    enh_trans = [convert(enh_path+'/'+name) for name in lms]\n",
        "    temp['ori'] = ori_trans\n",
        "    temp['adv'] = adv_trans\n",
        "    temp['enh'] = enh_trans\n",
        "    temp['enh_ori'] = enh_ori_trans\n",
        "    trans[text[i]] = temp\n",
        "  translations.append(trans)\n",
        "  t.close()\n",
        "  gr.close()\n",
        "\n",
        "trans_dict['long'] = translations[0]\n",
        "trans_dict['medium'] = translations[1]\n",
        "trans_dict['short'] = translations[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYW7IzjsvIKh"
      },
      "source": [
        "trans_dict['long'] = translations[0]\n",
        "trans_dict['medium'] = translations[1]\n",
        "trans_dict['short'] = translations[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXzduIQcCCA"
      },
      "source": [
        "with open('deepxi_trans.pickle', 'wb') as e:\n",
        "  pickle.dump(trans_dict, e, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD3MEsstqF1"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGY5DNsDv3m-"
      },
      "source": [
        "wer = {}\n",
        "with open('deepxi_trans.pickle', 'rb') as e:\n",
        "  wer = pickle.load(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSCh9rnHtmFa"
      },
      "source": [
        "wer.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYikTjJB3Ifn"
      },
      "source": [
        "wer['short']['sample-006936.wav']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}