{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepspeechB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGZ1qZXuEzBV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd drive/MyDrive/IW06-07/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WlA6cwHEYE0"
      },
      "source": [
        "!pip3 install speechbrain\n",
        "!pip3 install deepspeech-gpu\n",
        "!pip3 install jiwer\n",
        "%pip install torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVpbPs3XLK9x"
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0hstOHUElAJ"
      },
      "source": [
        "import deepspeech\n",
        "import wave\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "from jiwer import compute_measures\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFAjAQh_RZT2"
      },
      "source": [
        "Deepspeech model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3yFO45JF0ae"
      },
      "source": [
        "model_file_path = 'deepspeech-0.9.3-models.pbmm'\n",
        "model = deepspeech.Model(model_file_path)\n",
        "scorer_file_path = 'deepspeech-0.9.3-models.scorer'\n",
        "model.enableExternalScorer(scorer_file_path)\n",
        "lm_alpha = 0.931289039105002\n",
        "lm_beta = 1.1834137581510284\n",
        "model.setScorerAlphaBeta(lm_alpha, lm_beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU3Svy3LuL7x"
      },
      "source": [
        "def convert(model, audio):\n",
        "  w = wave.open(audio, 'r')\n",
        "  assert int(w.getframerate()) == 16000\n",
        "  data = np.frombuffer(w.readframes(w.getnframes()), dtype=np.int16)\n",
        "  return model.stt(data)\n",
        "def diff(o, a, e, c):\n",
        "  # adv-ori, enh-ori, enh-act\n",
        "  if len(o) == 0:\n",
        "    if len(a) != 0:\n",
        "      return 0, compute_measures(a, o)['wer'], compute_measures(c, e)['wer']\n",
        "    return 0, 0, compute_measures(c, e)['wer']\n",
        "  return compute_measures(o, a)['wer'], compute_measures(o, e)['wer'], compute_measures(c, e)['wer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0X3iQrYRm_9"
      },
      "source": [
        "Speech Enhancement Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDYxYwCVRmoJ"
      },
      "source": [
        "enhance_model = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/mtl-mimic-voicebank\",\n",
        "    savedir=\"pretrained_models/mtl-mimic-voicebank\",\n",
        "    run_opts={\"device\":\"cuda\"},\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s7ZQrctV9Es"
      },
      "source": [
        "Adversarial Dataset A Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5YhoFe9RsE"
      },
      "source": [
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJHXFilC8emh"
      },
      "source": [
        "commands = ['down', 'go', 'left', 'right', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
        "original = './adversarial_dataset-B/Adversarial-Examples/Original-Examples/'\n",
        "adversarial = './adversarial_dataset-B/Adversarial-Examples/Adversarial-Examples/'\n",
        "enhanced = './enhanced/baseline/'\n",
        "# get wav files \n",
        "audio_files = {}\n",
        "for command in commands:\n",
        "  files = os.listdir(original+command)\n",
        "  audio_files[command] = files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W5AmUvhR22g"
      },
      "source": [
        "def call_enhance_wer(adv_command, editor):\n",
        "  # get commands\n",
        "  wer_stats = [0]*3\n",
        "  tot = 0\n",
        "  for command in commands:\n",
        "    temp_stats = [0]*3\n",
        "    if command == adv_command:\n",
        "      continue\n",
        "    # dir adv_command/command\n",
        "    files = audio_files[command]\n",
        "    base_adv_path = adversarial + adv_command + '/' + command + '/'\n",
        "    base_ori_path = original + '/' + command + '/'\n",
        "    base_enh_path = enhanced + adv_command + '/' + command + '/'\n",
        "    Path(base_enh_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    editor.write(adv_command + ', ' + command + '\\n')\n",
        "\n",
        "    for audio in files:\n",
        "      ori = convert(model, base_ori_path + audio)\n",
        "      a_file = base_adv_path + audio\n",
        "      enhanced_audio = enhance_model.enhance_file(a_file)\n",
        "      enh_name = base_enh_path + audio\n",
        "      torchaudio.save(enh_name, enhanced_audio.unsqueeze(0).cpu(), sample_rate=16000, bits_per_sample=16)\n",
        "\n",
        "      enh = convert(model, enh_name)\n",
        "      adv = convert(model, a_file)\n",
        "      editor.write(ori + ', ' + adv + ', ' + enh + '\\n')\n",
        "      \n",
        "      # adv-ori, enh-ori, enh-act\n",
        "      stats = diff(ori, adv, enh, command)\n",
        "      for i in range(len(stats)):\n",
        "        temp_stats[i] += stats[i]\n",
        "        wer_stats[i] += stats[i]\n",
        "      tot += 1\n",
        "\n",
        "    editor.write('\\nadv-ori, enh-ori, enh-act: ')\n",
        "    editor.write(str([i/len(files) for i in temp_stats]) + '\\n\\n')\n",
        "\n",
        "  editor.write('\\n\\nadv-ori, enh-ori, enh-act: ')\n",
        "  editor.write(str([i/tot for i in wer_stats]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ehsR7FW5MN"
      },
      "source": [
        "## Call models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRhHrTpWejh"
      },
      "source": [
        "for command in commands:\n",
        "  editor = open(enhanced + command + '/stats.txt', 'w+')\n",
        "  call_enhance_wer(command, editor)\n",
        "  editor.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdHMPKvRjC7V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}